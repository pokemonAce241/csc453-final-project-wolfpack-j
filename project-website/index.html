<!DOCTYPE html>
<html>
  <head>
    <title>IoT Data Auralization/Musicalization</title>
    <style>
      img {
        border: 2px solid black;
      }
      p {
        max-width: 800px;
      }
      body {
        margin-left: 20px;
      }
    </style>
  </head>

  <body>
    <h1>CSC 453 - IoT Systems</h1>
    <h2>IoT Data Auralization/Musicalization</h2>
    <h3>Wolfpack J - Jason Benckert, Cameron Finley, Stanton Parham, WeiRui Wang</h3>
    <h4>Description</h4>
    <p>
      The objective of our project is to “auralize” and “musicalize” IoT data in
      an effort to help the visually impaired “visualize” the data. We have
      created sounds based on data collected from sensors in a particular
      environment that essentially auralizes that environment and its
      characteristics. This technology could be used by anyone for entertainment
      or utility purposes although it is mainly directed towards the visually
      impaired. In the case that a visually impaired person cannot easily navigate
      and respond to their environment, our product could potentially help them.
      This is not necessarily a new idea since things like this have existed for
      ages (e.g. crosswalk alarms), but the way in which we have designed and
      implemented it certainly is.
    </p>

    <h4>Design</h4>
    <p>
      For the project, our system uses an MQTT broker for data transfer between
      the client’s interface and sensors connected to a Raspberry Pi. The user can
      control the web application’s audio by toggling the sounds produced by different
      sensors on and off.  This allows the user to hear only the sounds that can best help them.
    </p>
    <br />

    <img src="system-architecture.png" alt="System architecture" height="300">
    <p>
      Above you can see a diagram of our system.  The light, motion, temperature, and
      humidity sensors are connected to a Raspberry Pi which is connected to the IoT
      service in IBM Cloud.  The web application is subscribed to the topics for these
      values on the IBM Cloud and receives them at a regular interval.
    </p>
    <br />

    <img src="rpi-wiring-diagram.png" alt="Raspberry Pi wiring diagram" height="300">
    <p>
      Above is the wiring diagram for the sensors to our Raspberry Pi.  Wiring the
      individual sensors was relatively simple even though the overall diagram looks
      a bit cluttered due to all of the sensors being present. It should be noted
      that due to limitations of fritzing the sensor brands aren't the same as the
      real thing by have the same input and output. To clarify, the motion sensor is
      a MPU6050 and the humidity/temperature sensor is a DHT 11.
    </p>
    <br />

    <h4>Process Pictures</h4>
    <p>Below are some pictures of us working on the project.</p>
    <img src="setting-up-rpi.JPG" alt="Testing DHT11 sensor" height="300">
    <p>
      Above you can see us testing the temperature sensor on the DHT11 sensor by
      dunking it into a cup of ice.
    </p>
    <br />

    <img src="setting-up-ibm-cloud.JPG" alt="Setting up IBM Cloud" height="300">
    <p>
      Above you can see us creating our device in IBM Cloud and generating our API key.
    </p>
    <br />

    <img src="writing-interface.JPG" alt="Writing web application interface" height="300">
    <p>
      Above you can see us writing the code for our web application.
    </p>
    <br />

    <p>
      For further details, see our GitHub page at
      <a href="https://github.ncsu.edu/stparham/csc453-final-project-wolfpack-j">https://github.ncsu.edu/stparham/csc453-final-project-wolfpack-j</a>.
      You can find all of our code, our demo steps, and our final report there.
      The repository should be accessible by anyone on NCSU's Enterprise GitHub.
    </p>
    <br />
    <br />
    <br />
  </body>
</html>
